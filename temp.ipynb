{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\anaconda3\\envs\\ssg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from tools import get_image_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 406, 722, 406)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_dimensions('img_p0_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline_generator.py\n",
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Pydantic models for validation\n",
    "class SlideDistribution(BaseModel):\n",
    "    sub_slide: int\n",
    "    sub_slide_title: str | None = None\n",
    "    sub_slide_subtitle: str | None = None\n",
    "    key_points: List[str]\n",
    "\n",
    "class SectionOutline(BaseModel):\n",
    "    heading: str\n",
    "    num_content_slides: int\n",
    "    slide_distribution: List[SlideDistribution]\n",
    "\n",
    "class DocumentOutline(BaseModel):\n",
    "    title: str\n",
    "    subtitle: str | None = None  # Make subtitle optional with default None\n",
    "    sections: List[SectionOutline]\n",
    "\n",
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a slide-outline assistant.  \n",
    "Given the document title and a list of section summaries, produce a JSON object matching this schema:\n",
    "\n",
    "{{\n",
    "  \"title\": <string>,           // main deck title\n",
    "  \"subtitle\": <string>,        // optional subtitle or author\n",
    "  \"sections\": [\n",
    "    {{\n",
    "      \"heading\": <string>,     // section heading\n",
    "      \"num_content_slides\": <integer >= 1>,  \n",
    "      \"slide_distribution\": [\n",
    "        {{\n",
    "          \"sub_slide\": <integer>,  // Sub slide number\n",
    "          \"sub_slide_title\": <string>,  // Sub slide title\n",
    "          \"sub_slide_subtitle\": <string>,  // Sub slide subtitle (optional)\n",
    "          \"key_points\": [<string>, ...]  // 1-3 bullet points for this slide. If more than 3, move to next sub-slide\n",
    "        }},\n",
    "        ...\n",
    "      ]\n",
    "    }},\n",
    "    …\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Use no extra keys. Constrain total slides (sum of num_content_slides) to be at most {max_slides}.\n",
    "Here are the inputs:\n",
    "\n",
    "Document Title:\n",
    "{title}\n",
    "\n",
    "Section Summaries:\n",
    "{summaries}\n",
    "\"\"\"\n",
    "\n",
    "def generate_outline(title: str, summaries: List[dict], max_slides: int = 15) -> DocumentOutline:\n",
    "    # Fill prompt\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        title=title,\n",
    "        summaries=\"\\n\".join(f\"- {s['title']}: {s['summary']}\" for s in summaries),  # Include section titles\n",
    "        max_slides=max_slides\n",
    "    )\n",
    "\n",
    "    # Call the LLM\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1200,  # Increased token limit for longer responses\n",
    "    )\n",
    "\n",
    "    # Parse JSON\n",
    "    content = resp.choices[0].message.content.strip()\n",
    "    try:\n",
    "        outline_dict = json.loads(content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise RuntimeError(f\"LLM returned invalid JSON:\\n{content}\") from e\n",
    "\n",
    "    # Validate with Pydantic\n",
    "    try:\n",
    "        outline = DocumentOutline.model_validate(outline_dict)\n",
    "    except ValidationError as e:\n",
    "        raise RuntimeError(f\"Outline validation failed:\\n{e}\") from e\n",
    "\n",
    "    return outline\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage; replace with your real summaries\n",
    "    doc_title = \"Q2 Marketing Strategy Review\"\n",
    "    section_summaries = [{'title': 'Brief Assessment:', 'summary': 'Yue Sai, a once prestigious Chinese cosmetics brand, lost relevance due to failed repositionings, leading to low awareness among younger consumers. L’Oréal faces the challenge of reviving the brand in a competitive market shaped by rising local players and digital consumption. Younger Chinese consumers prefer skin care rooted in tradition. Competitors like Herborist succeed with modern branding rooted in traditional Chinese medicine. Digital platforms and experiential retail offer better engagement than TV ads. L’Oréal must align its city-tier strategy with a clear brand identity to meet evolving consumer expectations.'}, {'title': 'Decision Problem:', 'summary': \"To reposition Yue Sai in China's cosmetics market, L'Oréal must conduct thorough market research to understand current trends and consumer preferences. By leveraging Yue Sai's heritage and reputation, L'Oréal can revamp the brand's image to appeal to modern Chinese consumers. Implementing innovative marketing strategies and product offerings tailored to the local market will be crucial in regaining relevance and increasing market share.\"}, {'title': 'Criteria:', 'summary': \"This slide examines Yue Sai's sales performance and product-market fit. Sales data is analyzed to project revenue, while market research assesses how well products align with target segment needs. Factors like local relevance and demographic responsiveness are considered to ensure products meet customer preferences.\"}, {'title': '3. Strategic Fit', 'summary': \"This slide evaluates the alignment of alternatives with L'Oréal's brand vision and mission. Each alternative is scored based on its compatibility with the company's brand values.\"}, {'title': '4. Risk of Attrition', 'summary': \"Learn how to measure customer loyalty and growth with a focus on retaining existing customers and attracting new ones. Evaluate customer retention metrics, purchase behavior, and changes in demographics to ensure the product's success in the market.\"}, {'title': '5. Execution Complexity', 'summary': 'This slide evaluates the implementation difficulty of the proposed alternative by assessing costs related to resources, budget constraints, production, and logistics. It highlights the importance of considering these factors when making decisions.'}, {'title': 'Moderate Risk', 'summary': 'In a highly competitive digital space, the brand risks alienating older loyalists while facing strong local rivals like Herborist and Chando.'}, {'title': 'Attrition Risk', 'summary': 'Appealing to a broader audience can lead to increased retention rates, but may also dilute brand prestige.'}, {'title': 'Execution', 'summary': 'To achieve moderate growth, implement targeted digital campaigns, invest in TCM research and development, and expand offerings in premium tiers.'}, {'title': 'Very High', 'summary': 'Managing multiple channels can significantly raise complexity and costs.'}, {'title': 'Recommendation: Alternative 1 - Yue Sai for Modern Young Women', 'summary': \"Alternative 1 offers a clear strategy for Yue Sai to rebuild its brand with luxury appeal and cultural relevance through TCM, targeting modern, health-conscious young women in China. This unique position within L'Oreal's portfolio distinguishes Yue Sai from other luxury brands, ensuring long-term growth and market relevance.\"}]\n",
    "    outline = generate_outline(doc_title, section_summaries, max_slides=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outline(outline: DocumentOutline, file_path: str):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(outline.model_dump(), f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_outline(outline, \"outline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_outline(file_path: str) -> DocumentOutline:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return DocumentOutline.model_validate(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = load_outline(\"outline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outline.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    outline = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19776\\1420854632.py:69: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  slide_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_19776\\1420854632.py:98: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_str = slide_chain.run({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 11 slides to 'generated_slide_content.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Literal, Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# ------------------------------\n",
    "# 🎯 Pydantic Models\n",
    "# ------------------------------\n",
    "class SlideContent(BaseModel):\n",
    "    bullets: List[str] = Field(..., min_items=1, max_items=7)\n",
    "    speaker_notes: str\n",
    "    \n",
    "    image_caption: List[str] = Field(default_factory=list)\n",
    "    flowchart: Literal[\"True\", \"False\"]\n",
    "    flowchart_description: Optional[str] = None\n",
    "\n",
    "class SlideOutput(BaseModel):\n",
    "    section: str\n",
    "    sub_slide: int\n",
    "    slide_content: SlideContent\n",
    "\n",
    "# ------------------------------\n",
    "# 🧠 Prompt Template\n",
    "# ------------------------------\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an AI assistant generating PowerPoint slide content. Your goal is to make the presentation look professional and engaging. Avoid suggesting images with charts or graphs, unless the slide is about a chart or graph.\n",
    "\n",
    "Slide Title: {slide_title}\n",
    "Slide Subtitle: {slide_subtitle}\n",
    "Key Points:\n",
    "{key_ideas}\n",
    "\n",
    "Your task:\n",
    "1. Rewrite the key points into 3–5 concise bullet points suitable for a slide.\n",
    "2. Write speaker notes that expand on the bullet points.\n",
    "3. Determine if an image will help explain the slide.\n",
    "    If yes, Set \"image_caption\" to a list containing a 1-sentence caption for the image (e.g., [\"A skincare shelf in a Chinese department store\"], [\"Flowchart showing digital vs retail touchpoints\"], [\"Logo of Yue Sai brand\"])\n",
    "    Captions should be clear, descriptive, and useful for image search.\n",
    "    If no, Set \"image_caption\" to an empty list.\n",
    "\n",
    "4. Decide if a flowchart is helpful. If yes:\n",
    "   - Set \"flowchart\" to \"True\"\n",
    "   - Provide a 1-sentence flowchart_description\n",
    "   If not:\n",
    "   - Set \"flowchart\" to \"False\"\n",
    "   - flowchart_description may be null\n",
    "\n",
    "Return only a **valid JSON** with the following structure:\n",
    "\n",
    "{{\n",
    "  \"bullets\": [\"...\"],\n",
    "  \"speaker_notes\": \"...\",\n",
    "  \"image_caption\": [\"...\"],     \n",
    "  \"flowchart\": \"True\" or \"False\",\n",
    "  \"flowchart_description\": \"...\"\n",
    "}}\n",
    "\n",
    "Do NOT use markdown formatting or backticks. Return raw JSON only.\n",
    "                                          \n",
    "Return only a valid JSON object. Do not include extra text. Use double quotes. Ensure proper commas and no trailing commas.\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------\n",
    "# ⚙️ Initialize LangChain\n",
    "# ------------------------------\n",
    "llm = ChatOpenAI(temperature=0.4, model=\"gpt-4o\")\n",
    "slide_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# ------------------------------\n",
    "# 📂 Load Outline\n",
    "# ------------------------------\n",
    "with open(\"outline.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    outline = json.load(f)\n",
    "\n",
    "# ------------------------------\n",
    "# 🚀 Generate Slide Content\n",
    "# ------------------------------\n",
    "results = []\n",
    "\n",
    "def safe_parse_response(response_str: str) -> Optional[SlideContent]:\n",
    "    try:\n",
    "        response_json = json.loads(response_str)\n",
    "        return SlideContent.model_validate(response_json)\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        print(f\"\\n❌ Validation failed:\\n{e}\\n→ Raw response:\\n{response_str}\\n{'-'*60}\")\n",
    "        return None\n",
    "\n",
    "for section in outline[\"sections\"]:\n",
    "    for slide in section[\"slide_distribution\"]:\n",
    "        slide_title = section[\"heading\"]\n",
    "        slide_subtitle = f\"Slide {slide['sub_slide']}\"\n",
    "        key_ideas = \"\\n\".join(f\"- {pt}\" for pt in slide[\"key_points\"])\n",
    "\n",
    "        try:\n",
    "            # Run the LLM\n",
    "            response_str = slide_chain.run({\n",
    "                \"slide_title\": slide_title,\n",
    "                \"slide_subtitle\": slide_subtitle,\n",
    "                \"key_ideas\": key_ideas\n",
    "            })\n",
    "\n",
    "            # Parse and validate\n",
    "            slide_content = safe_parse_response(response_str)\n",
    "\n",
    "            if slide_content:\n",
    "                result = SlideOutput(\n",
    "                    section=slide_title,\n",
    "                    sub_slide=slide[\"sub_slide\"],\n",
    "                    slide_content=slide_content\n",
    "                )\n",
    "                results.append(result.model_dump())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error on slide '{slide_title} - {slide['sub_slide']}': {e}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 💾 Save Results\n",
    "# ------------------------------\n",
    "with open(\"generated_slide_content.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Saved {len(results)} slides to 'generated_slide_content.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 slides from generated_slide_content.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the generated slide content\n",
    "with open(\"generated_slide_content.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    slide_content = json.load(f)\n",
    "\n",
    "# Print the loaded content for verification\n",
    "print(f\"Loaded {len(slide_content)} slides from generated_slide_content.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 slides from updated_slide_content.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the generated slide content\n",
    "with open(\"updated_slide_content.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    updated_slide_content = json.load(f)\n",
    "\n",
    "# Print the loaded content for verification\n",
    "print(f\"Loaded {len(updated_slide_content)} slides from updated_slide_content.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from tavily import TavilyClient\n",
    "from typing import Optional\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")  # Or replace with your string\n",
    "tavily = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "# ------------------------------\n",
    "# 📥 Image Search + Download\n",
    "# ------------------------------\n",
    "def search_and_download_image_from_web(\n",
    "    query: str,\n",
    "    output_dir: str = \"images\",\n",
    "    filename: Optional[str] = None,\n",
    "    index: int = 0\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Search Tavily for an image and download the first result.\n",
    "\n",
    "    Args:\n",
    "        query (str): The image search query (e.g., image caption).\n",
    "        output_dir (str): Directory to save the downloaded image.\n",
    "        filename (str, optional): Filename for the image (defaults to slugified query).\n",
    "        index (int): Which image result to download (0 = top result).\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved image, or None if no image found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"🔍 Searching for image: {query}\")\n",
    "        results = tavily.search(query, include_images=True)\n",
    "\n",
    "        if not results or not results.get(\"images\"):\n",
    "            print(\"⚠️ No images found for this query.\")\n",
    "            return None\n",
    "\n",
    "        image_url = results[\"images\"][index]\n",
    "        print(f\"📸 Found image URL: {image_url}\")\n",
    "\n",
    "        # Prepare save path\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        safe_filename = filename or f\"{query.lower().replace(' ', '_')[:50]}.jpg\"\n",
    "        image_path = safe_filename\n",
    "\n",
    "        # Download and save image\n",
    "        img_data = requests.get(image_url).content\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "\n",
    "        print(f\"✅ Image saved at: {image_path}\")\n",
    "        return image_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to download image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Building image index...\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m updated_slide_content = copy.deepcopy(slide_content)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m slide \u001b[38;5;129;01min\u001b[39;00m updated_slide_content:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     captions = \u001b[43mslide\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mslide_content\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mimage_caption\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m captions:\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tools import get_best_image\n",
    "from multimodal_rag import build_image_index\n",
    "import copy\n",
    "\n",
    "image_index = build_image_index(\"./images\")\n",
    "used_images = set()\n",
    "\n",
    "# Create a deep copy of slide_content to avoid modifying the original\n",
    "updated_slide_content = copy.deepcopy(slide_content)\n",
    "\n",
    "for slide in updated_slide_content:\n",
    "    captions = slide['slide_content']['image_caption']\n",
    "    if not captions:\n",
    "        continue\n",
    "        \n",
    "    for caption in captions:\n",
    "        # Try to get image from RAG first\n",
    "        image_path, confidence = get_best_image(caption, image_index)\n",
    "\n",
    "        # if confidence is less than 0.30, get from web\n",
    "        if confidence < 0.30:\n",
    "            image_path = search_and_download_image_from_web(caption)\n",
    "            \n",
    "        if image_path:\n",
    "            used_images.add(image_path)\n",
    "            # Add image path to slide content\n",
    "            if 'image_paths' not in slide['slide_content']:\n",
    "                slide['slide_content']['image_paths'] = []\n",
    "            slide['slide_content']['image_paths'].append(image_path)\n",
    "            print(f\"Caption: {caption}\")\n",
    "            print(f\"Image path: {image_path}\\n\")\n",
    "            print(f\"Confidence: {confidence}\")\n",
    "\n",
    "# Save updated slide content to a new JSON file\n",
    "with open(\"updated_slide_content.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_slide_content, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import get_all_image_dimensions\n",
    "get_all_image_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "milgya\n",
      "milgya\n",
      "milgya\n",
      "milgya\n",
      "milgya\n",
      "milgya\n",
      "milgya\n"
     ]
    }
   ],
   "source": [
    "def update_slide_content_with_dimensions(slide_content):\n",
    "    \"\"\"\n",
    "    Update slide content with image dimensions from image_metadata.json\n",
    "    \n",
    "    Args:\n",
    "        slide_content (list): List of slide content dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        list: Updated slide content with image dimensions\n",
    "    \"\"\"\n",
    "    updated_content = copy.deepcopy(slide_content)\n",
    "    \n",
    "    for slide in updated_content:\n",
    "        if 'slide_content' in slide and 'image_paths' in slide['slide_content']:\n",
    "            image_paths = slide['slide_content']['image_paths']\n",
    "            dimensions = []\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                img_info = get_image_dimensions(img_path)\n",
    "                if img_info:\n",
    "                    name, width, height = img_info\n",
    "                    dimensions.append({\n",
    "                        'path': img_path,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "            \n",
    "            slide['slide_content']['image_dimensions'] = dimensions\n",
    "    \n",
    "    return updated_content\n",
    "\n",
    "# Update the slide content with dimensions\n",
    "updated_slide_content = update_slide_content_with_dimensions(updated_slide_content)\n",
    "\n",
    "# Save updated content with dimensions\n",
    "with open(\"updated_slide_content.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_slide_content, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing layout for slide Brief Assessment 1\n",
      "Error parsing layout for slide Decision Problem 1\n",
      "Error parsing layout for slide Criteria 1\n",
      "Error parsing layout for slide Strategic Fit 1\n",
      "Error parsing layout for slide Risk of Attrition 1\n",
      "Error parsing layout for slide Execution Complexity 1\n",
      "Error parsing layout for slide Moderate Risk 1\n",
      "Error parsing layout for slide Attrition Risk 1\n",
      "Error parsing layout for slide Execution 1\n",
      "Error parsing layout for slide Very High 1\n",
      "Error parsing layout for slide Recommendation 1\n",
      "Slide layouts have been generated and saved to slide_layouts.json\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tools import get_image_dimensions\n",
    "\n",
    "def get_slide_layout(slide_content):\n",
    "    client = OpenAI()\n",
    "    \n",
    "    # Check if slide has images\n",
    "    has_images = bool(slide_content['slide_content'].get('image_paths', []))\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a professional presentation designer. Design a layout for this slide content. ENSURE THERE IS NO OVERLAP OF TEXT AND IMAGES.\n",
    "    \n",
    "    Guidelines:\n",
    "    - Create a balanced layout that emphasizes key points\n",
    "    - Position text and images strategically\n",
    "    - Use appropriate font sizes (12-24)\n",
    "    - Consider visual hierarchy\n",
    "    - Ensure readability\n",
    "    - {'Maintain image aspect ratio' if has_images else 'Center text in the slide since there are no images'}\n",
    "    - Standard PowerPoint slide dimensions are (10x5.625 inches)\n",
    "    - Ensure the text does not overflow the slide.\n",
    "    \n",
    "    Slide Content:\n",
    "    Section: {slide_content['section']}\n",
    "    Sub-slide: {slide_content['sub_slide']}\n",
    "    Bullets: {slide_content['slide_content']['bullets']}\n",
    "    {f\"Image Caption: {slide_content['slide_content'].get('image_caption', [])}\" if has_images else \"\"}\n",
    "    {f\"Image Paths: {slide_content['slide_content'].get('image_paths', [])}\" if has_images else \"\"}\n",
    "    {f\"Image Dimensions: {slide_content['slide_content'].get('image_dimensions', [])}\" if has_images else \"\"}\n",
    "    \n",
    "    Return the layout in this JSON format:\n",
    "    {{\n",
    "        \"slide_dimensions\": {{\n",
    "            \"width\": 10,\n",
    "            \"height\": 5.625\n",
    "        }},\n",
    "        \"title_box\": {{\n",
    "            \"x\": number,\n",
    "            \"y\": number,\n",
    "            \"width\": number,\n",
    "            \"height\": number,\n",
    "            \"font_size\": number,\n",
    "            \"padding\": number\n",
    "        }},\n",
    "        \"subtitle_box\": {{\n",
    "            \"x\": number,\n",
    "            \"y\": number,\n",
    "            \"width\": number,\n",
    "            \"height\": number,\n",
    "            \"font_size\": number,\n",
    "            \"padding\": number\n",
    "        }},\n",
    "        \"bulleted\": boolean,\n",
    "        \"content_font_size\": number,\n",
    "        \"text_box\": {{\n",
    "            \"layout\": \"left/right/top/bottom\",\n",
    "            \"x\": number,\n",
    "            \"y\": number,\n",
    "            \"width\": number,\n",
    "            \"height\": number,\n",
    "            \"padding\": number\n",
    "        }},\n",
    "        \"image_paths\": [\"string\"],\n",
    "        \"image_boxes\": [\n",
    "            {{\n",
    "                \"layout\": \"left/right/top/bottom\",\n",
    "                \"x\": number,\n",
    "                \"y\": number,\n",
    "                \"width\": number,\n",
    "                \"height\": number,\n",
    "                \"padding\": number\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        layout = json.loads(response.choices[0].message.content.strip())\n",
    "        # Add title and text from slide_content\n",
    "        layout[\"title\"] = slide_content['section']\n",
    "        layout[\"subtitle\"] = f\"Sub-slide {slide_content['sub_slide']}\" if slide_content['sub_slide'] > 1 else \"\"\n",
    "        layout[\"text\"] = slide_content['slide_content']['bullets']\n",
    "        return layout\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing layout for slide {slide_content['section']} {slide_content['sub_slide']}\")\n",
    "        return None\n",
    "\n",
    "# Process each slide and generate layouts\n",
    "slide_layouts = []\n",
    "for slide in updated_slide_content:\n",
    "    layout = get_slide_layout(slide)\n",
    "    if layout:\n",
    "        slide_layouts.append(layout)\n",
    "\n",
    "# Save layouts to JSON file\n",
    "with open(\"slide_layouts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(slide_layouts, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Slide layouts have been generated and saved to slide_layouts.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
